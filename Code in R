# we are going to lean how to identify the emotion on the face by using mirosoft Cognitive Services
#open a Rstudio
#install packages like
> install.packages("httr")
> install.packages("XML")
> install.packages("stringr")
> install.packages("ggplot2")

#now use above installed packages in ur program
> library("httr")
> library("XML")
> library("stringr")
> library("ggplot2")

#Now select an source Image from the source url
> img.url='.....................'
# Define Microsoft API URL to request data ....................
> URL.emoface = 'https://api.projectoxford.ai/emotion/v1.0/recognize'
# Define access key (access key is available via: https://www.microsoft.com/cognitive-services/en-us/emotion-api)
> emotionKEY = 'XXXX'
 
# Define image
> mybody = list(url = img.url)
 
# Request data from Microsoft
>  faceEMO = POST(
  url = URL.emoface,
  content_type('application/json'), add_headers(.headers = c('Ocp-Apim-Subscription-Key' = emotionKEY)),
  body = mybody,
  encode = 'json'
)#face data to detect
 
# Show request results (if Status=200, request is okay)
> faceEMO
 
# Reuqest results from face analysis
> sachin= httr::content(faceEMO)[[1]]
> sachin
# Define results in data frame
> o<-as.data.frame(as.matrix(sachin$scores))
 
# Make some transformation
> o$V1 <- lapply(strsplit(as.character(o$V1 ), "e"), "[", 1)
> o$V1<-as.numeric(o$V1)
> colnames(o)[1] <- "Level"
 
# Define names
> o$Emotion<- rownames(o)
 
# Mak> e plot
> ggplot(data=o, aes(x=Emotion, y=Level)) +
  geom_bar(stat="identity")
  
 ## TEST
 
